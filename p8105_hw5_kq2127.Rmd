---
title: "p8105_hw5_kq2127"
author: "Kristal Quispe"
date: "11/6/2019"
output: md_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1

```{r}
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

```


Writting the Function
```{r}
replace_na = function(x) {
  if (is.numeric(x)) {
    x[is.na(x)] = round(mean(x, na.rm = TRUE),1)
    x }
  else if (is.character(x)) {
    x[is.na(x)] = "virginica"
    x
  }
}
```


Testing the function
```{r}
replace_na(iris_with_missing[[1]])
replace_na(iris_with_missing[[2]])
replace_na(iris_with_missing[[3]])
replace_na(iris_with_missing[[4]])
replace_na(iris_with_missing[[5]])
```

Applying the function and mapping
```{r}
output = map_dfr(iris_with_missing, replace_na)

output
```

# Problem 2

```{r}
pb2_df = 
  list.files(
    path = "./data/",
    pattern = "*.csv",
    full.names = TRUE) %>% 
  map_df(read_csv, .id = "input") %>% 
  rename(id = input) %>% 
  mutate(
    id = as.numeric(id),
    arm = ifelse(id <= 10, "con", "exp"),
    id = recode(id,
       '11' = 1,
       '12' = 2,
       '13' = 3,
       '14' = 4,
       '15' = 5,
       '16' = 6,
       '17' = 7,
       '18' = 8,
       '19' = 9,
       '20' = 10)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observation") %>%
  select(id, arm, everything())

pb2_df %>% 
  mutate (id = as.factor(id)) %>% 
  ggplot(aes(x = week, y = observation, color = id, group = id)) + 
  geom_point(alpha =.5) +
  geom_line() +
  facet_grid(~arm) +
  ggtitle("Observations over time") 


```
Over time, the control arm tends to have an overall constant trend: there are dips and rises in observation values over time that mostly average out. On the other hand the experimental arm tends to increase in its observations values over time. 


# Problem 3



```{r}
set.seed(1)

sim_regression = function(n = 30, beta0 = 2, beta1) {
  
  sim_data = tibble(
    x = rnorm(n = 30),
    y = 2 + beta1 * x + rnorm(n = 30, 0, 50)
  )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  
   pb3_df = tibble(
    beta1_hat = broom::tidy(ls_fit)[2, 2] %>% pull(),
    p = broom::tidy(ls_fit)[2, 5] %>% pull ()
  )
print(pb3_df)
}

```


Testting the function
```{r}
sim_regression(beta1 = 0)
```


Generating 100 datasets
```{r}
output_2 = 
  rerun(100, sim_regression(beta1 = 0 )) %>% 
  bind_rows()

output_2

```

In regards to the simulation samples, 10000 was on the verge of crashing my computer so I could only run 100.


Rerun function with beta1 as 1-6
```{r}
sim_results = 
  tibble(beta1 = c(1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = beta1, ~rerun(100, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)

sim_results
```

Plots
```{r}
sim_results %>% 
  mutate(
    power = ifelse(p < 0.05, 1, 0)) %>% 
  ggplot(aes(x = beta1, y = mean(power))) + 
  geom_point(alpha =.5) +
  geom_line() +
  ggtitle("Association between effect size and power") +
  labs(y = "Power")

```

Due to computer capabilities, I could not run each beta1 more than 100 times each without crashing my computer , thus the plot does not represent the actual relationship between effect size and power. But, from my stats classe I know that as effect size increases, the power of a test also increases. 

 
```{r}
sim_results %>% 
  group_by(beta1) %>% 
  mutate(avg_beta1_hat = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta1, y = avg_beta1_hat)) + 
  geom_point(alpha =.5) +
  geom_line() 
```

Due to small sample size, I could not generate a plot that is comprehensive of the beta 1 and  average beta 1 hat relationship. As we increase the number of runs, beta 1 hat should approache the true value of beta 1.


```{r}
sim_results %>% 
  filter (p < 0.05) %>% 
  group_by(beta1) %>% 
  mutate(avg_beta1_hat = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta1, y = avg_beta1_hat)) + 
  geom_point() +
  geom_line()
```

The sample average of beta 1 hat across tests for which the null is rejected is not approximately equal to the true value of beta 1. This is because, in filtering out the beta 1 hat approximations where we fail to reject the null, we reduce the number of samples. As samples decrease, beta 1 hat gets further and further away from the true value of beta 1. 

I had to render the documnet to a md_document beucase after my second plot, I kept getting the following error which would not let me knit: pandoc document conversion failed with error 1022. My computer was also not able to process 10,000 samples as specified in question 3, it kept almost crashing so I could only run 100 samples per beta 1. 
